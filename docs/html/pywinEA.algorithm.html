
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>pywinEA.algorithm &#8212; PyWinEA  documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pywinEA.dataset" href="pywinEA.dataset.html" />
    <link rel="prev" title="pywinEA package" href="pywinEA.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pywinEA.dataset.html" title="pywinEA.dataset"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="pywinEA.html" title="pywinEA package"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">PyWinEA  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="modules.html" >pywinEA</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="pywinEA.html" accesskey="U">pywinEA package</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="pywinea-algorithm">
<h1>pywinEA.algorithm<a class="headerlink" href="#pywinea-algorithm" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-pywinEA.algorithm.basic">
<span id="pywinea-algorithm-basic-module"></span><h2>pywinEA.algorithm.basic module<a class="headerlink" href="#module-pywinEA.algorithm.basic" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pywinEA.algorithm.basic.GA">
<em class="property">class </em><code class="sig-prename descclassname">pywinEA.algorithm.basic.</code><code class="sig-name descname">GA</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.basic.GA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="pywinEA.interface.html#pywinEA.interface.algorithm.GAbase" title="pywinEA.interface.algorithm.GAbase"><code class="xref py py-class docutils literal notranslate"><span class="pre">pywinEA.interface.algorithm.GAbase</span></code></a></p>
<p>Basic implementation of a mono-objective genetic algorithm (although the algorithm
is mono-objective, multi-objective metrics can be coupled as long as they return a single value).
In its initialization, you must specify a fitness function (pywin.fitness module) or a scikit-learn
classifier and a Scikit-learn cross validation iterator. Additionally it is necessary to specify a
population model (pywin.population.Population). Alternatively it is possible to indicate the population
size, in this case a “simple” population will be created (pywin.population.Population).
Additionally, it is necessary to provide the basic operators required by the genetic algorithm
indicated below.</p>
<dl class="simple">
<dt>fitness: sklearn.base.BaseEstimator or pywin.fitness.interface.FitnessStrategy</dt><dd><p>If a scikit-learn estimator is provided it is necessary to supply the cv parameter.</p>
</dd>
<dt>cv: &lt;optional&gt; sklearn.BaseCrossValidator (Splitter class)</dt><dd><p>Scikit-learn cross validator iterable.</p>
</dd>
<dt>population: &lt;optional&gt; pywin.population.Population</dt><dd><p>If a population is not provided it is necessary to specify the population size using argument
population_size.</p>
</dd>
<dt>population_size: &lt;optionally&gt; int</dt><dd><p>Only necessary if a population is not provided. By default the algorithm will create a basic
population (pywin.population.Population).</p>
</dd>
<dt>selection: &lt;optional&gt; pywin.selection.interface.SelectionStrategy</dt><dd><p>Individual selection strategy. By default pywin.selection.TournamentSelection (with two gladiators,
a single winner and sampling without replacement).</p>
</dd>
<dt>elitism: &lt;optional&gt; float or pywin.operators.interface.ElitismStrategy</dt><dd><p>If a float (0-1) is provided, the algorithm will use pywin.operators.BestFitness to select the
proportion of individuals best fitted according to the indicated percentage. Otherwise it is
necessary to provide an operator that inherits from the ElitismStrategy interface.</p>
</dd>
<dt>elitism_rate: &lt;optional&gt; float</dt><dd><p>Percentage of individuals that will form the elite. Only required if an ElitismStrategy operator
has been provided in the elitism parameter.</p>
</dd>
<dt>annihilation: &lt;optional&gt; float or pywin.operators.interface.AnnihilationStrategy</dt><dd><p>If a float number is provided, the worst individuals will be removed from the population by the
indicated percentage and the population will be filled with new random or elite individuals (The
percentage can be modified using the fill_with_elite parameter). In this case the algorithm will use the
AnnihilateWorse annihilation strategy.
If an Annihilation instance is provided it is necessary to specify the annihilation_rate parameter.</p>
</dd>
<dt>annihilation_rate: &lt;optional&gt; float</dt><dd><p>If a float number is provided, the worst individuals will be removed from the population by the
indicated percentage and the population will be filled with new random individuals or elite individuals
(The percentage can be modified using the fill_with_elite parameter).</p>
</dd>
<dt>fill_with_elite: &lt;optional&gt; float</dt><dd><p>Percentage of annihilated individuals to be replaced from elite individuals. To specify this parameter
it is necessary to provide elitism parameter.</p>
</dd>
<dt>crossover: &lt;optional&gt; pywin.operators.interface.CrossOverStrategy</dt><dd><p>Individual cross-over strategy. By default pywin.operators.OnePoint.</p>
</dd>
<dt>mutation: &lt;optional&gt; pywin.operators.interface.MutationStrategy</dt><dd><p>Mutation strategy used to introduce changes in the population. With some strategies it may be necessary
to indicate the mutation_rate parameter.</p>
</dd>
<dt>mutation_rate &lt;optional&gt; float</dt><dd><p>A parameter that indicates the probability of a random change occurring in a given individual. If this
argument is provided without a mutation argument by default pywin.operators.RandomMutation will be used.</p>
</dd>
<dt>imputer: &lt;optional&gt; pywin.imputation.interface.ImputationStrategy</dt><dd><p>Strategy to handle missing values. The missing values will be imputed for each individual in the
population using the individual features.</p>
</dd>
<dt>generations: int</dt><dd><p>Number of generations (the minimum number of generations is 1).</p>
</dd>
<dt>positive_class: &lt;optional&gt; int</dt><dd><p>Class that will be considered as positive class, the rest of the classes will be considered as negative
classes.
If a value is provided the class labels will be transformed -&gt; Binary Classification.
Otherwise they will not be modified -&gt; Multiclass classification.</p>
</dd>
<dt>random_state<span class="classifier">&lt;optional&gt; int</span></dt><dd><p>Random seed.</p>
</dd>
<dt>id<span class="classifier">&lt;optional&gt; str</span></dt><dd><p>Algorithm identifier</p>
</dd>
</dl>
<p>best_features: (Getter) Return a list with the best features found by the algorithm.</p>
<p>get_current_generation: (Getter) Return the current generation of the algorithm.</p>
<p>population: (Getter) Return the current population of the algorithm.</p>
<p>population_fitness: (Getter) Return the fitness of the current generation of the algorithm.</p>
<p>best_performance: (Getter) Return a dict with the score and the best performance achieved.</p>
<p>fitness: (Getter / Setter) Algorithm fitness strategy.</p>
<p>generations: (Getter / Setter) Algorithm number of generations.</p>
<p>selection: (Getter / Setter) Algorithm selection strategy.</p>
<p>elitism: (Getter / Setter) Algorithm elitism strategy.</p>
<p>elitism_rate: (Getter / Setter) Algorithm elitism rate.</p>
<p>annihilation: (Getter / Setter) Algorithm annihilation strategy.</p>
<p>annihilation_rate: (Getter / Setter) Algorithm annihilation rate.</p>
<p>fill_with_elite: (Getter / Setter) Percentage of annihilated individuals replaced from the elite.</p>
<p>mutation: (Getter / Setter) Algorithm mutation strategy.</p>
<p>mutation_rate: (Getter / Setter) Algorithm mutation rate.</p>
<p>imputer: (Getter / Setter) Algorithm imputation strategy.</p>
<p>crossover: (Getter / Setter) Algorithm crossover strategy.</p>
<p>positive_class: (Getter / Setter) Number of the class selected as positive class.</p>
<p>random_state: (Getter / Setter) Random state.</p>
<p>id: (Getter / Setter) Algorithm identifier.</p>
<dl class="simple">
<dt>set_features(features): Allows you to assign the labels of the columns (the names of the predictor variables).</dt><dd><p>If this function is not used before using the fit method, the corresponding numerical value will be assigned
to the position of the predictor variable. It also can be used after training step.</p>
</dd>
</dl>
<p>fit(X, y): Start algorithm execution.</p>
<p>continue_training(generations): Continue training the algorithm for an extra number of generations.</p>
<dl class="simple">
<dt>predict(X): Predict the labels of the predictor variables. It is necessary that the model</dt><dd><p>has been previously adjusted with the fit method.</p>
</dd>
<dt>training_evolution(): Returns the parameters monitored during training.It returns a dictionary with the</dt><dd><dl class="simple">
<dt>following scheme:</dt><dd><dl class="simple">
<dt>:key total_fitness</dt><dd><p>Dictionary that stores as a key the generation and as a value the total fitness of the population.</p>
</dd>
<dt>:key best_fitness</dt><dd><p>Dictionary that stores as a key the generation and as a value the best individual fitness.</p>
</dd>
<dt>:key mean_num_features</dt><dd><p>Dictionary that stores as a key the generation and as a value the average number of features
in the population.</p>
</dd>
<dt>:key std_num_features</dt><dd><p>Dictionary that stores as a key the generation and as a value the standard deviation in the number
of features in the population.</p>
</dd>
<dt>:key best_num_features</dt><dd><p>Dictionary that stores as a key the generation and as a value the number of features in best individual.</p>
</dd>
<dt>:key best_(cv_score)</dt><dd><p>Dictionary that stores as a key the generation and as a value the performance measure of the best
individual.</p>
</dd>
<dt>:key mean_(cv_score)</dt><dd><p>Dictionary that stores as a key the generation and as a value the average performance in performance
measure population.</p>
</dd>
<dt>:key std_(cv_score)</dt><dd><p>Dictionary that stores as a key the generation and as a value the standard deviation in performance
measure in population.</p>
</dd>
<dt>:key best_features</dt><dd><p>Array that in the first position stores the best combination of features found by the algorithm and in
the second position the fitness of the individual.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>get_dataset(): Function that returns the dataset with the selected features.</p>
<p>set_population(new_individuals): Method that allows to select a new population of solutions.</p>
<p>save(file_name, dir_name, overwrite): This function allows to save the model into a file.</p>
<p>load_model(file_name, dir_name): &lt;class method&gt; This function allows to load a model from a file.</p>
<dl class="method">
<dt id="pywinEA.algorithm.basic.GA.best_features">
<em class="property">property </em><code class="sig-name descname">best_features</code><a class="headerlink" href="#pywinEA.algorithm.basic.GA.best_features" title="Permalink to this definition">¶</a></dt>
<dd><p>It allows to obtain the best combination of features found by the algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list
Best combination of features.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.basic.GA.best_performance">
<em class="property">property </em><code class="sig-name descname">best_performance</code><a class="headerlink" href="#pywinEA.algorithm.basic.GA.best_performance" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the largest value found for the selected fitness function.</p>
<dl class="simple">
<dt>:return dict</dt><dd><p>Score and maximum value achieved by the algorithm.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.basic.GA.continue_training">
<code class="sig-name descname">continue_training</code><span class="sig-paren">(</span><em class="sig-param">generations: int</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.basic.GA.continue_training" title="Permalink to this definition">¶</a></dt>
<dd><p>This function allows to continue training the algorithm since the last generation.</p>
<blockquote>
<div><p>continue_training(generations: int)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>generations</strong> – int
Extra number of generations.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pywin.algorithms.BasicGA
Model fitted using the best feature combination.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.basic.GA.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X: numpy.ndarray</em>, <em class="sig-param">y: numpy.ndarray</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.basic.GA.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that begins the execution of the algorithm. First, it processes the class labels to adapt
them to a mono-class classification problem (only if positive_class has been provided). Then it initializes
a random population and calls the _core() method where the main logic of the algorithm is defined.</p>
<blockquote>
<div><p>fit(X: np.ndarray, y: np.ndarray)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – 2d-array
Values of the target variables.</p></li>
<li><p><strong>y</strong> – 1d-array
Labels of each condition.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pywin.algorithms.BasicGA
Model fitted using the best feature combination.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.basic.GA.get_dataset">
<code class="sig-name descname">get_dataset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.basic.GA.get_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that returns a dataset with the selected features and associated class labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>2d-array
Predictor variables.</p>
</dd>
</dl>
<dl class="simple">
<dt>:return 1d-array</dt><dd><p>Class labels.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.basic.GA.load">
<em class="property">classmethod </em><code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">file_name: str</em>, <em class="sig-param">dir_name: str = './_PyWinModels'</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.basic.GA.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Class method that allows retrieving models stored in .algorithms files. By default the files will be recovered
from _PyWinModels directory.</p>
<blockquote>
<div><p>load(file_name: str, dir_name: str = ‘./_PyWinModels’)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_name</strong> – str
File name.</p></li>
<li><p><strong>dir_name</strong> – &lt;optional&gt; str
Directory where the file is located.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pywin.algorithms.BasicGA
Model fitted using the best feature combination.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.basic.GA.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: numpy.ndarray</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.basic.GA.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that returns the predictions made by the best combination of model and features.</p>
<blockquote>
<div><p>predict(X: np.ndarray)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – 2d-array
Data that will be predicted.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>1d-array
Predictions.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.basic.GA.training_evolution">
<code class="sig-name descname">training_evolution</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.basic.GA.training_evolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that returns a dictionary with the data collected throughout the algorithm search.
You can use the function plot_evolution() from pywin.visualization.Plotter to display it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>dict
Dictionary with the total fitness of the population and best individual, the number
of features in the population and best individual, and information on the performance achieved.</p>
</dd>
</dl>
<dl class="simple">
<dt>:return str</dt><dd><p>Score used to evaluate fitness.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pywinEA.algorithm.nsga2">
<span id="pywinea-algorithm-nsga2-module"></span><h2>pywinEA.algorithm.nsga2 module<a class="headerlink" href="#module-pywinEA.algorithm.nsga2" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pywinEA.algorithm.nsga2.NSGA2">
<em class="property">class </em><code class="sig-prename descclassname">pywinEA.algorithm.nsga2.</code><code class="sig-name descname">NSGA2</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.nsga2.NSGA2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="pywinEA.interface.html#pywinEA.interface.algorithm.MOAbase" title="pywinEA.interface.algorithm.MOAbase"><code class="xref py py-class docutils literal notranslate"><span class="pre">pywinEA.interface.algorithm.MOAbase</span></code></a></p>
<p>Implementation of the multi-objective NSGAII algorithm based on:</p>
<blockquote>
<div><p>K. Deb, A. Pratap, S. Agarwal and T. Meyarivan, “A fast and elitist multiobjective genetic algorithm:
NSGA-II,” in IEEE Transactions on Evolutionary Computation, vol. 6, no. 2, pp. 182-197, April 2002.</p>
</div></blockquote>
<p>As many target functions as desired can be added from the fitness sub-module. You can also treat the number
of features as an objective function (to be minimized) by indicating the parameter optimize_features as true.
To evaluate the evolution of the algorithm, the hypervolume indicator is used. This metric has been implemented
using the inclusion-exclusion algorithm. It must be taken into account that the larger the population or the
more objectives have to be maximized, the higher the computational cost will be.</p>
<dl>
<dt>fitness: pywin.interface.FitnessStrategy / pywin.fitness / list</dt><dd><p>If the parameter optimize_features is True, a unique fitness function of the fitness submodule can be provided
(also a list with several functions is allowed). If this parameter is selected as False it is necessary to
provide a list with at least two functions to optimize.</p>
</dd>
<dt>optimize_features: &lt;optional&gt; bool</dt><dd><p>If this parameter is true, the number of targets will be a function to optimize.</p>
</dd>
<dt>features_function: &lt;optional&gt; function</dt><dd><p>User-defined function that should receive a value called “individual” and  another value “tot_feats”. This f
unction should return a single value that will be maximized. By default this function will be:</p>
<blockquote>
<div><p>f(individual) = 1 - (len(individual.features) / len(all features))</p>
</div></blockquote>
<p>Important note: Functions cannot be defined as lambda functions as they are not serializable by the pickle
library and an error will be thrown.</p>
</dd>
<dt>population: &lt;optional&gt; pywin.population.Population</dt><dd><p>If a population is not provided it is necessary to specify the population size using argument
population_size.</p>
</dd>
<dt>population_size: &lt;optionally&gt; int</dt><dd><p>Only necessary if a population is not provided. By default the algorithm will create a basic
population (pywin.population.Population).</p>
</dd>
<dt>selection: &lt;optional&gt; pywin.selection.interface.SelectionStrategy</dt><dd><p>Individual selection strategy. By default pywin.selection.TournamentSelection (with two gladiators,
a single winner and sampling without replacement).</p>
</dd>
<dt>crossover: &lt;optional&gt; pywin.operators.interface.CrossOverStrategy</dt><dd><p>Individual cross-over strategy. By default pywin.operators.OnePoint.</p>
</dd>
<dt>mutation: &lt;optional&gt; pywin.operators.interface.MutationStrategy</dt><dd><p>Mutation strategy used to introduce changes in the population. With some strategies it may be necessary
to indicate the mutation_rate parameter.</p>
</dd>
<dt>mutation_rate &lt;optional&gt; float</dt><dd><p>A parameter that indicates the probability of a random change occurring in a given individual. If this
argument is provided without a mutation argument by default pywin.operators.RandomMutation will be used.</p>
</dd>
<dt>imputer: &lt;optional&gt; pywin.imputation.interface.ImputationStrategy</dt><dd><p>Strategy to handle missing values. The missing values will be imputed for each individual in the
population using the individual features.</p>
</dd>
<dt>generations: int</dt><dd><p>Number of generations (the minimum number of generations is 1).</p>
</dd>
<dt>positive_class: &lt;optional&gt; int</dt><dd><p>Class that will be considered as positive class, the rest of the classes will be considered as negative
classes.
If a value is provided the class labels will be transformed -&gt; Binary Classification.
Otherwise they will not be modified -&gt; Multiclass classification.</p>
</dd>
<dt>random_state<span class="classifier">&lt;optional&gt; int</span></dt><dd><p>Random seed.</p>
</dd>
<dt>id<span class="classifier">&lt;optional&gt; str</span></dt><dd><p>Algorithm identifier</p>
</dd>
</dl>
<p>best_features: (Getter) Return a list with the best features in each solution.</p>
<p>get_current_generation: (Getter) Return the current generation of the algorithm.</p>
<p>population: (Getter) Return the current population of the algorithm.</p>
<dl class="simple">
<dt>population_fitness: (Getter) Return the fitness of the current generation of the algorithm (This consists of</dt><dd><p>instances of Solution).</p>
</dd>
</dl>
<p>best_performance: (Getter) Return a dict with the score and the best performance achieved for each solution.</p>
<p>fitness: (Getter / Setter) Algorithm fitness strategy.</p>
<p>features_function: (Getter / Setter) Function to evaluate the number of features.</p>
<p>generations: (Getter / Setter) Algorithm number of generations.</p>
<p>selection: (Getter / Setter) Algorithm selection strategy.</p>
<p>mutation_rate: (Getter / Setter) Algorithm mutation_rate.</p>
<p>imputer: (Getter / Setter) Algorithm imputation strategy.</p>
<p>crossover: (Getter / Setter) Algorithm crossover strategy.</p>
<p>positive_class: (Getter / Setter) Algorithm selection strategy.</p>
<p>random_state: (Getter / Setter) Algorithm selection strategy.</p>
<p>id: (Getter / Setter) Algorithm selection strategy.</p>
<dl class="simple">
<dt>set_features(features): Allows you to assign the labels of the columns (the names of the predictor variables).</dt><dd><p>If this function is not used before using the fit method, the corresponding numerical value will be assigned
to the position of the predictor variable. It also can be used after training step.</p>
</dd>
</dl>
<p>fit(X, y): Start algorithm execution.</p>
<p>continue_training(generations): Continue training the algorithm for an extra number of generations.</p>
<p>predict(X): Method NOT available for NSGA2.</p>
<dl class="simple">
<dt>training_evolution(): Returns the parameters monitored during training.It returns a dictionary with the</dt><dd><dl class="simple">
<dt>following scheme:</dt><dd><dl class="field-list simple">
<dt class="field-odd">key hypervolume</dt>
<dd class="field-odd"><p>Hypervolume indicator in each generation.</p>
</dd>
<dt class="field-even">key num_solutions_front</dt>
<dd class="field-even"><p>Number of solutions on the Pareto front in each generation.</p>
</dd>
<dt class="field-odd">key best_values</dt>
<dd class="field-odd"><p>Best values of each function in each generation.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>get_dataset(): Function that returns all the dataset and class labels.</p>
<p>set_population(new_individuals): Method that allows to select a new population of solutions.</p>
<p>save(file_name, dir_name, overwrite): This function allows to save the model into a file.</p>
<p>load_model(file_name, dir_name): &lt;class method&gt; This function allows to load a model from a file.</p>
<dl class="method">
<dt id="pywinEA.algorithm.nsga2.NSGA2.continue_training">
<code class="sig-name descname">continue_training</code><span class="sig-paren">(</span><em class="sig-param">generations: int</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.nsga2.NSGA2.continue_training" title="Permalink to this definition">¶</a></dt>
<dd><p>This function allows to continue training the algorithm since the last generation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>generations</strong> – int
Extra number of generations.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>NSGA2</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.nsga2.NSGA2.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X: numpy.ndarray</em>, <em class="sig-param">y: numpy.ndarray</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.nsga2.NSGA2.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that begins the execution of the algorithm. First, it processes the class labels to adapt
them to a mono-class classification problem (only if positive_class has been provided). Then it initializes
a random population and calls the _core() method where the main logic of the algorithm is defined.</p>
<blockquote>
<div><p>fit(X: np.ndarray, y: np.ndarray)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – 2d-array
Values of the target variables.</p></li>
<li><p><strong>y</strong> – 1d-array
Labels of each condition.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pywin.algorithms.NSGA2
Model fitted using the best feature combination.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.nsga2.NSGA2.get_dataset">
<code class="sig-name descname">get_dataset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.nsga2.NSGA2.get_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that returns all the dataset and class labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>2d-array
Predictor variables.</p>
</dd>
</dl>
<dl class="simple">
<dt>:return 1d-array</dt><dd><p>Class labels.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.nsga2.NSGA2.training_evolution">
<code class="sig-name descname">training_evolution</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.nsga2.NSGA2.training_evolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that returns a dictionary with the data collected throughout the algorithm search.
You can use the function plot_evolution() from pywin.visualization.Plotter to display it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>dict
Dictionary with the evolution of the hypervolume indicator, number of solutions on the non-dominated
front and best values for each objective function.</p>
</dd>
</dl>
<dl class="simple">
<dt>:return str</dt><dd><p>Scores used to evaluate fitness.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pywinEA.algorithm.nsga2.Solution">
<em class="property">class </em><code class="sig-prename descclassname">pywinEA.algorithm.nsga2.</code><code class="sig-name descname">Solution</code><span class="sig-paren">(</span><em class="sig-param">values: list</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.nsga2.Solution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class that represents a possible solution with the values of each of the objective functions.</p>
<dl class="method">
<dt id="pywinEA.algorithm.nsga2.Solution.restart">
<code class="sig-name descname">restart</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.nsga2.Solution.restart" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset all values in the solution.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="pywinEA.algorithm.nsga2.calculate_crowding">
<code class="sig-prename descclassname">pywinEA.algorithm.nsga2.</code><code class="sig-name descname">calculate_crowding</code><span class="sig-paren">(</span><em class="sig-param">solutions: list</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.nsga2.calculate_crowding" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to calculate crowding for all solutions using _crowding_distance() method for each solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>solutions</strong> – list
List with all solutions.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pywinEA.algorithm.nsga2.restart_solutions">
<code class="sig-prename descclassname">pywinEA.algorithm.nsga2.</code><code class="sig-name descname">restart_solutions</code><span class="sig-paren">(</span><em class="sig-param">solutions</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.nsga2.restart_solutions" title="Permalink to this definition">¶</a></dt>
<dd><p>Method that resets the values of each solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>solutions</strong> – list</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-pywinEA.algorithm.spea2">
<span id="pywinea-algorithm-spea2-module"></span><h2>pywinEA.algorithm.spea2 module<a class="headerlink" href="#module-pywinEA.algorithm.spea2" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pywinEA.algorithm.spea2.SPEA2">
<em class="property">class </em><code class="sig-prename descclassname">pywinEA.algorithm.spea2.</code><code class="sig-name descname">SPEA2</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.SPEA2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="pywinEA.interface.html#pywinEA.interface.algorithm.MOAbase" title="pywinEA.interface.algorithm.MOAbase"><code class="xref py py-class docutils literal notranslate"><span class="pre">pywinEA.interface.algorithm.MOAbase</span></code></a></p>
<p>Implementation of the multi-objective SPEA2 algorithm based on:</p>
<blockquote>
<div><dl class="simple">
<dt>“SPEA2: Improving the Strength Pareto Evolutionary Algorithm for Multiobjective Optimization January 2001</dt><dd><p>Conference: Evolutionary Methods for Design, Optimization and Control with Applications to Industrial
Problems. Proceedings of the EUROGEN’2001. Athens. Greece, September 19-21. Eckart Zitzler, Marco Laumanns
and Lothar Thiele”</p>
</dd>
</dl>
</div></blockquote>
<p>As many target functions as desired can be added from the fitness sub-module. You can also treat the number
of features as an objective function (to be minimized) by indicating the parameter optimize_features as true.
To evaluate the evolution of the algorithm, the hypervolume indicator is used. This metric has been implemented
using the inclusion-exclusion algorithm. It must be taken into account that the larger the population or the
more objectives have to be maximized, the higher the computational cost will be.</p>
<dl>
<dt>fitness: pywin.fitness.interface.FitnessStrategy / list</dt><dd><p>If the parameter optimize_features is True, a unique fitness function of the fitness submodule can be provided
(also a list with several functions is allowed). If this parameter is selected as False it is necessary to
provide a list with at least two functions to optimize.</p>
</dd>
<dt>optimize_features: &lt;optional&gt; bool</dt><dd><p>If this parameter is true, the number of targets will be a function to optimize.</p>
</dd>
<dt>features_function: &lt;optional&gt; function</dt><dd><p>User-defined function that should receive a value called “individual” and  another value “tot_feats”. This f
unction should return a single value that will be maximized. By default this function will be:</p>
<blockquote>
<div><p>f(individual) = 1 - (len(individual.features) / len(all features))</p>
</div></blockquote>
<p>Important note: Functions cannot be defined as lambda functions as they are not serializable by the pickle
library and an error will be thrown.</p>
</dd>
<dt>population: &lt;optional&gt; pywin.population.Population</dt><dd><p>If a population is not provided it is necessary to specify the population size using argument
population_size.</p>
</dd>
<dt>population_size: &lt;optionally&gt; int</dt><dd><p>Only necessary if a population is not provided. By default the algorithm will create a basic
population (pywin.population.Population).</p>
</dd>
<dt>archive_length: &lt;optional&gt; int</dt><dd><p>Archive size. By default it will be equal to the population size.</p>
</dd>
<dt>distance: &lt;optional&gt; str</dt><dd><p>Distance used to estimate the density of solutions. By default the Euclidean distance will be used.
Currently available distances: ‘euclidean’, ‘minkowski’, ‘cosine’ and ‘canberra’</p>
</dd>
<dt>selection: &lt;optional&gt; pywin.selection.interface.SelectionStrategy</dt><dd><p>Individual selection strategy. By default pywin.selection.TournamentSelection (with two gladiators,
a single winner and sampling without replacement).</p>
</dd>
<dt>crossover: &lt;optional&gt; pywin.operators.interface.CrossOverStrategy</dt><dd><p>Individual cross-over strategy. By default pywin.operators.OnePoint.</p>
</dd>
<dt>mutation: &lt;optional&gt; pywin.operators.interface.MutationStrategy</dt><dd><p>Mutation strategy used to introduce changes in the population. With some strategies it may be necessary
to indicate the mutation_rate parameter.</p>
</dd>
<dt>mutation_rate &lt;optional&gt; float</dt><dd><p>A parameter that indicates the probability of a random change occurring in a given individual. If this
argument is provided without a mutation argument by default pywin.operators.RandomMutation will be used.</p>
</dd>
<dt>imputer: &lt;optional&gt; pywin.imputation.interface.ImputationStrategy</dt><dd><p>Strategy to handle missing values. The missing values will be imputed for each individual in the
population using the individual features.</p>
</dd>
<dt>generations: int</dt><dd><p>Number of generations (the minimum number of generations is 1).</p>
</dd>
<dt>positive_class: &lt;optional&gt; int</dt><dd><p>Class that will be considered as positive class, the rest of the classes will be considered as negative
classes.
If a value is provided the class labels will be transformed -&gt; Binary Classification.
Otherwise they will not be modified -&gt; Multiclass classification.</p>
</dd>
<dt>random_state<span class="classifier">&lt;optional&gt; int</span></dt><dd><p>Random seed.</p>
</dd>
<dt>id<span class="classifier">&lt;optional&gt; str</span></dt><dd><p>Algorithm identifier</p>
</dd>
</dl>
<p>best_features: (Getter) Return a list with the best features in each solution.</p>
<p>get_current_generation: (Getter) Return the current generation of the algorithm.</p>
<p>population: (Getter) Return the current population of the algorithm.</p>
<dl class="simple">
<dt>population_fitness: (Getter) Return the fitness of the current generation of the algorithm (This consists of</dt><dd><p>instances of Solution).</p>
</dd>
</dl>
<p>best_performance: (Getter) Return a dict with the score and the best performance achieved for each solution.</p>
<p>distance: (Getter / Setter) Distance used to evaluate the fitness density of the solutions.</p>
<p>archive_length: (Getter / Setter) Archive size.</p>
<p>fitness: (Getter / Setter) Algorithm fitness strategy.</p>
<p>features_function: (Getter / Setter) Function to evaluate the number of features.</p>
<p>generations: (Getter / Setter) Algorithm number of generations.</p>
<p>selection: (Getter / Setter) Algorithm selection strategy.</p>
<p>mutation_rate: (Getter / Setter) Algorithm mutation_rate.</p>
<p>imputer: (Getter / Setter) Algorithm imputation strategy.</p>
<p>crossover: (Getter / Setter) Algorithm crossover strategy.</p>
<p>positive_class: (Getter / Setter) Algorithm selection strategy.</p>
<p>random_state: (Getter / Setter) Algorithm selection strategy.</p>
<p>id: (Getter / Setter) Algorithm selection strategy.</p>
<dl class="simple">
<dt>set_features(features): Allows you to assign the labels of the columns (the names of the predictor variables).</dt><dd><p>If this function is not used before using the fit method, the corresponding numerical value will be assigned
to the position of the predictor variable. It also can be used after training step.</p>
</dd>
</dl>
<p>fit(X, y): Start algorithm execution.</p>
<p>continue_training(generations): Continue training the algorithm for an extra number of generations.</p>
<p>predict(X): Method NOT available for NSGA2.</p>
<dl class="simple">
<dt>training_evolution(): Returns the parameters monitored during training.It returns a dictionary with the</dt><dd><dl class="simple">
<dt>following scheme:</dt><dd><dl class="field-list simple">
<dt class="field-odd">key hypervolume</dt>
<dd class="field-odd"><p>Hypervolume indicator in each generation.</p>
</dd>
<dt class="field-even">key num_solutions_front</dt>
<dd class="field-even"><p>Number of solutions on the Pareto front in each generation.</p>
</dd>
<dt class="field-odd">key best_values</dt>
<dd class="field-odd"><p>Best values of each function in each generation.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>get_dataset(): Function that returns all the dataset and class labels.</p>
<p>set_population(new_individuals): Method that allows to select a new population of solutions.</p>
<p>save(file_name, dir_name, overwrite): This function allows to save the model into a file.</p>
<p>load_model(file_name, dir_name): &lt;class method&gt; This function allows to load a model from a file.</p>
<dl class="method">
<dt id="pywinEA.algorithm.spea2.SPEA2.continue_training">
<code class="sig-name descname">continue_training</code><span class="sig-paren">(</span><em class="sig-param">generations: int</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.SPEA2.continue_training" title="Permalink to this definition">¶</a></dt>
<dd><p>This function allows to continue training the algorithm since the last generation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>generations</strong> – int
Extra number of generations.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pywin.algorithms.SPEA2</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.spea2.SPEA2.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X: numpy.ndarray</em>, <em class="sig-param">y: numpy.ndarray</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.SPEA2.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that begins the execution of the algorithm. First, it processes the class labels to adapt
them to a mono-class classification problem (only if positive_class has been provided). Then it initializes
a random population and calls the _core() method where the main logic of the algorithm is defined.</p>
<blockquote>
<div><p>fit(X: np.ndarray, y: np.ndarray)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – 2d-array
Values of the target variables.</p></li>
<li><p><strong>y</strong> – 1d-array
Labels of each condition.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pywin.algorithms.SPEA2
Model fitted using the best feature combination.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.spea2.SPEA2.get_dataset">
<code class="sig-name descname">get_dataset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.SPEA2.get_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that returns all the dataset and class labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>2d-array
Predictor variables.</p>
</dd>
</dl>
<dl class="simple">
<dt>:return 1d-array</dt><dd><p>Class labels.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.spea2.SPEA2.training_evolution">
<code class="sig-name descname">training_evolution</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.SPEA2.training_evolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that returns a dictionary with the data collected throughout the algorithm search.
You can use the function plot_evolution() from pywin.visualization.Plotter to display it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>dict
Dictionary with the evolution of the hypervolume indicator, number of solutions on the non-dominated
front and best values for each objective function.</p>
</dd>
</dl>
<dl class="simple">
<dt>:return str</dt><dd><p>Scores used to evaluate fitness.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pywinEA.algorithm.spea2.Solution">
<em class="property">class </em><code class="sig-prename descclassname">pywinEA.algorithm.spea2.</code><code class="sig-name descname">Solution</code><span class="sig-paren">(</span><em class="sig-param">values: list</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.Solution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class that represents a possible solution with the values of each of the objective functions.</p>
<dl class="method">
<dt id="pywinEA.algorithm.spea2.Solution.restart">
<code class="sig-name descname">restart</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.Solution.restart" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset all values in the solution.</p>
</dd></dl>

<dl class="method">
<dt id="pywinEA.algorithm.spea2.Solution.select_density_to">
<code class="sig-name descname">select_density_to</code><span class="sig-paren">(</span><em class="sig-param">k</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.Solution.select_density_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Return fitness using density estimation to k-th neighbor. Based on</p>
<blockquote>
<div><dl class="simple">
<dt>“SPEA2: Improving the Strength Pareto Evolutionary Algorithm for Multiobjective Optimization January 2001</dt><dd><p>Conference: Evolutionary Methods for Design, Optimization and Control with Applications to Industrial
Problems. Proceedings of the EUROGEN’2001. Athens. Greece, September 19-21. Eckart Zitzler, Marco Laumanns
and Lothar Thiele”</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="pywinEA.algorithm.spea2.archive_selection">
<code class="sig-prename descclassname">pywinEA.algorithm.spea2.</code><code class="sig-name descname">archive_selection</code><span class="sig-paren">(</span><em class="sig-param">population: pywinEA.population.population.Population</em>, <em class="sig-param">archive_length: int</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.archive_selection" title="Permalink to this definition">¶</a></dt>
<dd><p>SPEA2 archive selection based on:</p>
<blockquote>
<div><dl class="simple">
<dt>“SPEA2: Improving the Strength Pareto Evolutionary Algorithm for Multiobjective Optimization January 2001</dt><dd><p>Conference: Evolutionary Methods for Design, Optimization and Control with Applications to Industrial
Problems. Proceedings of the EUROGEN’2001. Athens. Greece, September 19-21. Eckart Zitzler, Marco Laumanns
and Lothar Thiele”</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>population</strong> – pywin.population.Population</p></li>
<li><p><strong>archive_length</strong> – int</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list
List of solutions that make up the archive.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pywinEA.algorithm.spea2.density_estimation">
<code class="sig-prename descclassname">pywinEA.algorithm.spea2.</code><code class="sig-name descname">density_estimation</code><span class="sig-paren">(</span><em class="sig-param">solutions: list</em>, <em class="sig-param">k: int</em>, <em class="sig-param">distance</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.density_estimation" title="Permalink to this definition">¶</a></dt>
<dd><p>SPEA2 density estimation based on:</p>
<blockquote>
<div><dl class="simple">
<dt>“SPEA2: Improving the Strength Pareto Evolutionary Algorithm for Multiobjective Optimization January 2001</dt><dd><p>Conference: Evolutionary Methods for Design, Optimization and Control with Applications to Industrial
Problems. Proceedings of the EUROGEN’2001. Athens. Greece, September 19-21. Eckart Zitzler, Marco Laumanns
and Lothar Thiele”</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>solutions</strong> – list</p></li>
<li><p><strong>distance</strong> – function
Metric to evaluate the distance between two vectors.</p></li>
<li><p><strong>k</strong> – int
Neighbor from which the fitness density of the solution is calculated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pywinEA.algorithm.spea2.fitness_assignment">
<code class="sig-prename descclassname">pywinEA.algorithm.spea2.</code><code class="sig-name descname">fitness_assignment</code><span class="sig-paren">(</span><em class="sig-param">solutions: list</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.fitness_assignment" title="Permalink to this definition">¶</a></dt>
<dd><p>SPEA2 fitness assignment based on:</p>
<blockquote>
<div><dl class="simple">
<dt>“SPEA2: Improving the Strength Pareto Evolutionary Algorithm for Multiobjective Optimization January 2001</dt><dd><p>Conference: Evolutionary Methods for Design, Optimization and Control with Applications to Industrial
Problems. Proceedings of the EUROGEN’2001. Athens. Greece, September 19-21. Eckart Zitzler, Marco Laumanns
and Lothar Thiele”</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>solutions</strong> – list
List of possible solutions.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pywinEA.algorithm.spea2.restart_solutions">
<code class="sig-prename descclassname">pywinEA.algorithm.spea2.</code><code class="sig-name descname">restart_solutions</code><span class="sig-paren">(</span><em class="sig-param">solutions</em><span class="sig-paren">)</span><a class="headerlink" href="#pywinEA.algorithm.spea2.restart_solutions" title="Permalink to this definition">¶</a></dt>
<dd><p>Method that resets the values of each solution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>solutions</strong> – list</p>
</dd>
</dl>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">pywinEA.algorithm</a><ul>
<li><a class="reference internal" href="#module-pywinEA.algorithm.basic">pywinEA.algorithm.basic module</a></li>
<li><a class="reference internal" href="#module-pywinEA.algorithm.nsga2">pywinEA.algorithm.nsga2 module</a></li>
<li><a class="reference internal" href="#module-pywinEA.algorithm.spea2">pywinEA.algorithm.spea2 module</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="pywinEA.html"
                        title="previous chapter">pywinEA package</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="pywinEA.dataset.html"
                        title="next chapter">pywinEA.dataset</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/pywinEA.algorithm.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pywinEA.dataset.html" title="pywinEA.dataset"
             >next</a> |</li>
        <li class="right" >
          <a href="pywinEA.html" title="pywinEA package"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">PyWinEA  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="modules.html" >pywinEA</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="pywinEA.html" >pywinEA package</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Fernando García.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.4.0.
    </div>
  </body>
</html>